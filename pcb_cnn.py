# -*- coding: utf-8 -*-
"""PCB_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c94MYRjt2LJDs6MtBPINMHja7vTRIlzz
"""





"""## 구형과 안장형 두가지 클래스로 구분

"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# 데이터 경로 설정
data_dir = 'C:/Users/Hoon/Documents/PycharmProjects/pythonProject/Deep_Projcet/PCB/data'
categories = ['sattle', 'Goo']  # 두 가지 클래스로 분류

# 이미지 크기 설정
img_size = 100

# 데이터 로드 및 전처리
def load_data(data_dir, categories, img_size):
    data = []
    labels = []
    for category in categories:
        path = os.path.join(data_dir, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                resized_array = cv2.resize(img_array, (img_size, img_size))
                data.append(resized_array)
                labels.append(class_num)
            except Exception as e:
                pass
    return np.array(data), np.array(labels)

# 데이터 로드
X, y = load_data(data_dir, categories, img_size)

# 데이터 정규화
X = X / 255.0

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 모델 정의
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 데이터 증강
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# 모델 훈련
history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

# 예측
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# 예측 결과 시각화 (옵션)
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_test[i])
    plt.title(f'Actual: {categories[y_test[i]]}, Predicted: {categories[predicted_classes[i]]}')
    plt.axis('off')
plt.show()

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# 데이터 경로 설정
data_dir = '/content/drive/MyDrive/PCB_DATA/Image_Unsupervise'
categories = ['Spherical', 'Saddle-shaped']  # 두 가지 클래스로 분류

# 이미지 크기 설정
img_size = 100

# 데이터 로드 및 전처리
def load_data(data_dir, categories, img_size):
    data = []
    labels = []
    for category in categories:
        path = os.path.join(data_dir, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                resized_array = cv2.resize(img_array, (img_size, img_size))
                data.append(resized_array)
                labels.append(class_num)
            except Exception as e:
                pass
    return np.array(data), np.array(labels)

# 데이터 로드
X, y = load_data(data_dir, categories, img_size)

# 데이터 정규화
X = X / 255.0

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 모델 정의
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 데이터 증강
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# 모델 훈련
history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

# 예측
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# 예측 결과 시각화 (옵션)
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_test[i])
    plt.title(f'y: {categories[y_test[i]]}, Pred_y: {categories[predicted_classes[i]]}')
    plt.axis('off')
plt.show()

"""## 구형, 안장형, 원통형 세가지 클래스로 구분하는 코드

"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# 데이터 경로 설정
data_dir = '/content/drive/MyDrive/PCB_DATA/new_PCB_DATA'
categories = ['원통형', '안장형', '구형']  # 세 가지 클래스로 분류

# 이미지 크기 설정
img_size = 100

# 데이터 로드 및 전처리
def load_data(data_dir, categories, img_size):
    data = []
    labels = []
    for category in categories:
        path = os.path.join(data_dir, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                resized_array = cv2.resize(img_array, (img_size, img_size))
                data.append(resized_array)
                labels.append(class_num)
            except Exception as e:
                pass
    return np.array(data), np.array(labels)

# 데이터 로드
X, y = load_data(data_dir, categories, img_size)

# 데이터 정규화
X = X / 255.0

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 모델 정의
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 출력 레이어의 노드 수를 3으로 변경
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 데이터 증강
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# 모델 훈련
history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

# 예측
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# 예측 결과 시각화 (옵션)
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_test[i])
    plt.title(f'y: {categories[y_test[i]]}, pred_y: {categories[predicted_classes[i]]}')
    plt.axis('off')
plt.show()

"""+ 모델 저장, 그래프 출력 코드

"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# 데이터 경로 설정
data_dir = '/content/drive/MyDrive/PCB_DATA/new_PCB_DATA'
categories = ['Cylindrical', 'Saddle', 'Spherical']  # 세 가지 클래스로 분류

# 이미지 크기 설정
img_size = 100

# 데이터 로드 및 전처리
def load_data(data_dir, categories, img_size):
    data = []
    labels = []
    for category in categories:
        path = os.path.join(data_dir, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                resized_array = cv2.resize(img_array, (img_size, img_size))
                data.append(resized_array)
                labels.append(class_num)
            except Exception as e:
                pass
    return np.array(data), np.array(labels)

# 데이터 로드
X, y = load_data(data_dir, categories, img_size)

# 데이터 정규화
X = X / 255.0

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 모델 정의
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 출력 레이어의 노드 수를 3으로 변경
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 데이터 증강
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# 모델 훈련
history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))

# 모델 저장
model.save('/content/drive/MyDrive/PCB_DATA/saved_model/pcb_model.h5')
print("Model saved successfully.")

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

# 예측
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# 예측 결과 시각화
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_test[i])
    plt.title(f'y: {categories[y_test[i]]}, pred_y: {categories[predicted_classes[i]]}')
    plt.axis('off')
plt.show()

# 훈련 및 검증 정확도 그래프
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# 훈련 및 검증 손실 그래프
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

"""+ 성능평가지표"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 경로 설정
data_dir = '/content/drive/MyDrive/PCB_DATA/new_PCB_DATA'
categories = ['Cylindrical', 'Saddle', 'Spherical']  # 세 가지 클래스로 분류

# 이미지 크기 설정
img_size = 100

# 데이터 로드 및 전처리
def load_data(data_dir, categories, img_size):
    data = []
    labels = []
    for category in categories:
        path = os.path.join(data_dir, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                resized_array = cv2.resize(img_array, (img_size, img_size))
                data.append(resized_array)
                labels.append(class_num)
            except Exception as e:
                pass
    return np.array(data), np.array(labels)

# 데이터 로드
X, y = load_data(data_dir, categories, img_size)

# 데이터 정규화
X = X / 255.0

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 모델 정의
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 출력 레이어의 노드 수를 3으로 변경
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 데이터 증강
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# 모델 훈련
history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))

# 모델 저장
model.save('/content/drive/MyDrive/PCB_DATA/saved_model/pcb_model.h5')
print("Model saved successfully.")

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

# 예측
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# 혼동 행렬 계산
cm = confusion_matrix(y_test, predicted_classes)

# 혼동 행렬 시각화
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# 분류 보고서 출력
print("Classification Report:")
print(classification_report(y_test, predicted_classes, target_names=categories))


# 훈련 및 검증 정확도 그래프
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# 훈련 및 검증 손실 그래프
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

from google.colab import drive
drive.mount('/content/drive')

import cv2
import easyocr
import numpy as np
from spellchecker import SpellChecker

# 이미지 전처리 함수
def preprocess_image(image_path):
    # 이미지 로드
    image = cv2.imread(image_path)

    # Grayscale 변환
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Thresholding 적용 (이진화)
    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)

    # 노이즈 제거 (Gaussian Blur)
    denoised = cv2.GaussianBlur(thresh, (5, 5), 0)

    return denoised

# 이미지 기울기 보정 함수
def deskew(image):
    # 비어 있지 않은 픽셀 좌표 추출
    coords = np.column_stack(np.where(image > 0))
    # 최소 외접 직사각형을 구해 기울기 계산
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    # 이미지 중심을 기준으로 회전
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

# 철자 교정 함수
def correct_spelling(texts):
    spell = SpellChecker()
    corrected_texts = [spell.correction(word) for word in texts]
    return corrected_texts

# 이미지에서 텍스트 추출 함수
def extract_text(image_path):
    # 이미지 전처리
    preprocessed_image = preprocess_image(image_path)

    # 이미지 기울기 보정
    deskewed_image = deskew(preprocessed_image)

    # EasyOCR 모델 초기화 (한국어와 영어 지원)
    reader = easyocr.Reader(['ko', 'en'])

    # 텍스트 추출
    results = reader.readtext(deskewed_image, detail=0)

    # 철자 교정 적용
    corrected_texts = correct_spelling(results)

    return corrected_texts

# 메인 코드 실행
image_path = 'path_to_your_image.png'  # 처리할 이미지 파일 경로 설정
extracted_texts = extract_text(image_path)

# 추출된 텍스트 출력
print("Extracted and corrected texts:")
for text in extracted_texts:
    print(text)

"""r'C:\Users\Hoon\Documents\PycharmProjects\pythonProject\Deep_Projcet\PCB\data\Image_for_Text\25\img'"""

pip install easyocr

import easyocr
import json
import os

# EasyOCR reader 초기화 (한국어와 영어를 지원하도록 설정)
reader = easyocr.Reader(['ko', 'en'])

def extract_text_from_image(image_path):
    # OCR 수행
    results = reader.readtext(image_path)

    # 결과를 JSON 형식으로 변환
    text_data = []
    for (bbox, text, prob) in results:
        # numpy.int32 및 numpy.int64를 일반 int로 변환
        bbox = [[int(point[0]), int(point[1])] for point in bbox]

        entry = {
            "text": text,
            "confidence": float(prob),  # 확률을 float으로 변환
            "bounding_box": bbox
        }
        text_data.append(entry)

    return text_data

def save_text_data_to_json(text_data, output_json_path):
    # JSON 파일로 저장
    with open(output_json_path, 'w', encoding='utf-8') as json_file:
        json.dump(text_data, json_file, ensure_ascii=False, indent=4)

def process_image_folder(folder_path, output_json_folder):
    # 폴더 내의 모든 파일을 처리
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(folder_path, filename)
            text_data = extract_text_from_image(image_path)

            # JSON 파일로 저장할 경로 생성
            json_filename = os.path.splitext(filename)[0] + '.json'
            output_json_path = os.path.join(output_json_folder, json_filename)

            # JSON 파일로 저장
            save_text_data_to_json(text_data, output_json_path)
            print(f"{filename}에서 추출한 텍스트가 {output_json_path} 파일로 저장되었습니다.")

# 이미지 파일이 있는 폴더 경로
image_folder_path = '/content/drive/MyDrive/PCB_DATA/Text추출/Image_for_text'
# JSON 파일을 저장할 폴더 경로
output_json_folder = '/content/drive/MyDrive/PCB_DATA/Text추출/Image_to_text'
# 출력 폴더가 존재하지 않으면 생성
if not os.path.exists(output_json_folder):
    os.makedirs(output_json_folder)

# 이미지 폴더 처리
process_image_folder(image_folder_path, output_json_folder)

"""하나의 Json파일로 출력하는 Text 추출코드"""

import easyocr
import json
import os

# EasyOCR reader 초기화 (한국어와 영어를 지원하도록 설정)
reader = easyocr.Reader(['ko', 'en'])

def extract_text_from_image(image_path):
    # OCR 수행
    results = reader.readtext(image_path)

    # 텍스트만 추출하여 리스트로 반환
    texts = [text for _, text, _ in results]

    return texts

def process_image_folder_to_text_json(folder_path, output_json_path):
    images_data = []

    # 폴더 내의 모든 파일을 처리
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(folder_path, filename)
            texts = extract_text_from_image(image_path)

            # 이미지의 텍스트 데이터를 딕셔너리 형태로 저장
            image_data = {
                "image_name": filename,
                "texts": texts
            }
            images_data.append(image_data)

    # JSON 구조로 저장
    data = {
        "images": images_data
    }

    # JSON 파일로 저장 (파일 경로로 수정)
    with open(output_json_path, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, ensure_ascii=False, indent=4)

    print(f"모든 이미지의 텍스트가 {output_json_path} 파일로 저장되었습니다.")

# 이미지 파일이 있는 폴더 경로
image_folder_path = '/content/drive/MyDrive/PCB_DATA/Text추출/Image_for_text'

# JSON 파일로 저장할 경로 (파일명 포함)
output_json_path = '/content/drive/MyDrive/PCB_DATA/Text추출/Image_to_text/output.json'

# 이미지 폴더 처리하여 텍스트를 JSON 파일로 저장
process_image_folder_to_text_json(image_folder_path, output_json_path)

"""CRNN 코드

"""

# 1. 필요한 라이브러리 설치
!pip install torch torchvision opencv-python

# 2. 라이브러리 임포트
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import os
import torchvision.transforms as transforms

# 3. CRNN 모델 정의
class CRNN(nn.Module):
    def __init__(self, imgH, nc, nclass, nh):
        super(CRNN, self).__init__()
        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'

        self.cnn = nn.Sequential(
            nn.Conv2d(nc, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # height / 2
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # height / 4
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # height / 8
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1)),  # height / 16
            nn.Conv2d(512, 512, kernel_size=2, stride=1, padding=0),  # final height / 32
            nn.ReLU()
        )

        self.rnn = nn.LSTM(512, nh, bidirectional=True)

        self.fc = nn.Linear(nh * 2, nclass)

    def forward(self, input):
        conv = self.cnn(input)
        b, c, h, w = conv.size()
        assert h == 1, f"the height of conv must be 1, but got {h}"
        conv = conv.squeeze(2)
        conv = conv.permute(2, 0, 1)  # [w, b, c]

        output, _ = self.rnn(conv)
        output = self.fc(output)
        output = nn.functional.log_softmax(output, dim=2)

        return output

# 4. 데이터셋 클래스 정의
class TextImageDataset(Dataset):
    def __init__(self, image_dir, label_dir, transform=None):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.transform = transform
        self.images = [f for f in os.listdir(image_dir) if f.endswith('.png')]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = os.path.join(self.image_dir, self.images[idx])
        image = Image.open(img_name)

        # 이미지와 동일한 이름을 가진 텍스트 파일에서 레이블 읽기
        label_name = os.path.join(self.label_dir, os.path.splitext(self.images[idx])[0] + ".txt")
        with open(label_name, 'r') as label_file:
            label = label_file.readline().strip()

        if self.transform:
            image = self.transform(image)

        return image, label

# 5. 데이터 로더 정의
image_dir = "/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_image"
label_dir = "/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_text"

transform = transforms.Compose([
    transforms.Resize((32, 128)),  # 모델 입력 크기를 (32, 256)로 조정
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor()
])

dataset = TextImageDataset(image_dir=image_dir, label_dir=label_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# 6. CRNN 모델 생성 및 학습
nclass = 37  # 알파벳 26 + 숫자 10 + 공백 1 (총 37개의 클래스)
nh = 256  # RNN hidden units
crnn = CRNN(32, 1, nclass, nh)

criterion = nn.CTCLoss()
optimizer = optim.Adam(crnn.parameters(), lr=0.001)

num_epochs = 10  # 원하는 만큼 반복
for epoch in range(num_epochs):
    crnn.train()
    for images, labels in dataloader:
        # 레이블을 텍스트 시퀀스로 변환 (여기서는 간단히 ASCII 값 사용)
        targets = [torch.IntTensor([ord(c) for c in label]) for label in labels]
        targets = torch.cat(targets)
        target_lengths = torch.IntTensor([len(label) for label in labels])

        # 손실 계산
        outputs = crnn(images)
        output_lengths = torch.full((images.size(0),), outputs.size(0), dtype=torch.long)

        loss = criterion(outputs, targets, output_lengths, target_lengths)

        # 옵티마이저 업데이트
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')

# 7. 학습된 모델 저장
torch.save(crnn.state_dict(), 'crnn_trained.pth')
print("모델 학습이 완료되었고 저장되었습니다.")

# 8. 결과 확인 (학습된 모델로 테스트)
def recognize_text(image_path, crnn_model):
    image = Image.open(image_path)
    image = transform(image).unsqueeze(0)  # 배치 차원 추가
    crnn_model.eval()
    with torch.no_grad():
        preds = crnn_model(image)
        preds_size = torch.IntTensor([preds.size(0)])
        _, preds = preds.max(2)
        preds = preds.transpose(1, 0).contiguous().view(-1)

        # 텍스트 디코딩
        sim_pred = ''.join([chr(pred) for pred in preds])

    return sim_pred

# 테스트 이미지 경로 설정
test_image_path = '/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_test.png'

# 텍스트 인식 수행
recognized_text = recognize_text(test_image_path, crnn)
print('Recognized text:', recognized_text)

"""Simple CNN

"""

import cv2
import numpy as np
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout


# 이미지 및 텍스트 파일이 저장된 디렉토리
image_dir = "/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_image"   # 이미지 파일들이 저장된 경로로 변경하세요
text_dir ="/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_text"
   # 텍스트 파일들이 저장된 경로로 변경하세요

# 데이터와 레이블을 저장할 리스트
data = []
labels = []

# 이미지 파일과 텍스트 파일을 로드
for file_name in os.listdir(image_dir):
    if file_name.endswith('.png'):
        img_path = os.path.join(image_dir, file_name)
        text_path = os.path.join(text_dir, file_name.replace('.png', '.txt'))

        # 이미지 로드 및 전처리
        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        image = cv2.resize(image, (28, 28))  # 이미지 크기를 28x28로 조정
        image = image / 255.0  # 픽셀 값을 [0, 1] 범위로 정규화

        # 텍스트 파일에서 레이블 읽기
        with open(text_path, 'r') as file:
            label = file.read().strip()

        data.append(image)
        labels.append(label)

# 데이터를 numpy 배열로 변환
data = np.array(data).reshape(-1, 28, 28, 1)
labels = np.array(labels)

# 레이블을 숫자 인덱스로 변환 (문자를 숫자로 인코딩)
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# 데이터셋을 학습용과 검증용으로 분리
X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)



# CNN 모델 정의
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(label_encoder.classes_), activation='softmax')  # 클래스 수 만큼 출력
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 모델 학습
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# 모델 저장
model.save('courier_font_recognition_model.h5')

import cv2
import numpy as np
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout


# 이미지 및 텍스트 파일이 저장된 디렉토리
image_dir = "/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_image"   # 이미지 파일들이 저장된 경로로 변경하세요
text_dir ="/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_text"
   # 텍스트 파일들이 저장된 경로로 변경하세요

# 데이터와 레이블을 저장할 리스트
data = []
labels = []

# 이미지 파일과 텍스트 파일을 로드
for file_name in os.listdir(image_dir):
    if file_name.endswith('.png'):
        img_path = os.path.join(image_dir, file_name)
        text_path = os.path.join(text_dir, file_name.replace('.png', '.txt'))

        # 이미지 로드 및 전처리
        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        image = cv2.resize(image, (28, 28))  # 이미지 크기를 28x28로 조정
        image = image / 255.0  # 픽셀 값을 [0, 1] 범위로 정규화

        # 텍스트 파일에서 레이블 읽기
        with open(text_path, 'r') as file:
            label = file.read().strip()

        data.append(image)
        labels.append(label)

# 데이터를 numpy 배열로 변환
data = np.array(data).reshape(-1, 28, 28, 1)
labels = np.array(labels)

# 레이블을 숫자 인덱스로 변환 (문자를 숫자로 인코딩)
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# 데이터셋을 학습용과 검증용으로 분리
X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)



# CNN 모델 정의
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(label_encoder.classes_), activation='softmax')  # 클래스 수 만큼 출력
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 모델 학습
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# 모델 저장
model.save('courier_font_recognition_model.h5')

# 모델 불러오기
model = tf.keras.models.load_model('courier_font_recognition_model.h5')

# 테스트 이미지 로드 및 전처리
test_image = cv2.imread("/content/drive/MyDrive/PCB_DATA/Courier_font/Courier_test", cv2.IMREAD_GRAYSCALE)
test_image = cv2.resize(test_image, (28, 28))
test_image = test_image / 255.0
test_image = test_image.reshape(1, 28, 28, 1)

# 예측
prediction = model.predict(test_image)
predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])

print(f'예측된 텍스트: {predicted_class[0]}')